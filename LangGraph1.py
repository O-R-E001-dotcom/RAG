# Practicing LangGraph

from langgraph.graph import START, END, StateGraph, MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("OPENAI_API_KEY not found! Please set it in your .env file.")

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7,
    api_key=openai_api_key
)

# System prompt that defines assistant behavior
sys_msg = SystemMessage(
    content="You are a helpful customer support representative answering user questions. Be helpful and concise."
)

def assistant(state: MessagesState) -> dict:
    """
    The assistant node - processes messages and generates response.
    """
    # Combine system prompt with conversation history
    messages = [sys_msg] + state["messages"]
    
    # Get response from LLM
    response = llm.invoke(messages)
    
    # Return as state update
    return {"messages": [AIMessage(content=response.content)]}

# Create a StateGraph with MessagesState
builder = StateGraph(MessagesState)

# Add the assistant node
builder.add_node("assistant", assistant)

# Define the flow:
# START â†’ assistant â†’ END
builder.add_edge(START, "assistant")
builder.add_edge("assistant", END)

# Create a memory checkpointer (stores in memory)
memory = MemorySaver()

# Compile the graph WITH memory
agent = builder.compile(checkpointer=memory)

# Define a session ID for this conversation
session_id = "chat-session-001"

def run_conversation(user_input: str, thread_id: str = session_id):
    """
    Send a message to the agent and get response.
    âš ï¸ WARNING: Using default thread_id shares conversation acrosss all calls!
    In production, ALWAYS provide unique thread_id per user.
    """
    # Invoke the agent
    result = agent.invoke(
        {"messages": [HumanMessage(content=user_input)]},
        config={"configurable": {"thread_id": thread_id}}
    )
    
    # Print the conversation
    for message in result["messages"]:
        if isinstance(message, HumanMessage):
            print(f"\nğŸ‘¤ User: {message.content}")
        elif isinstance(message, AIMessage):
            print(f"ğŸ¤– Agent: {message.content}")
    
    print("\n" + "="*70)

# First message
run_conversation("I bought a charger")

# Follow-up question - does it remember?
run_conversation("It's not working, what should I do?")



